# Auth System - ëŒ€ëŸ‰ íŠ¸ë˜í”½ ëŒ€ì‘ ì¤€ë¹„ë„ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸

**ë¶„ì„ ë‚ ì§œ**: 2026-02-11
**ë¶„ì„ íŒ€**: 4ê°œ ì „ë¬¸ íŒ€ ë³‘ë ¬ ë¶„ì„
**ëŒ€ìƒ ì‹œìŠ¤í…œ**: FastAPI ê¸°ë°˜ ì¸ì¦/ì¸ê°€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤

---

## ğŸ“Š Executive Summary

### ì „ì²´ ì¤€ë¹„ë„ ì ìˆ˜: **8.5/10** ğŸŸ¢

| í‰ê°€ ì˜ì—­ | ì ìˆ˜ | ìƒíƒœ | ë¹„ê³  |
|---------|------|------|------|
| **ì•„í‚¤í…ì²˜ í™•ì¥ì„±** | 9/10 | ğŸŸ¢ ìš°ìˆ˜ | Stateless ì„¤ê³„ ì™„ë²½ |
| **ì„±ëŠ¥ ìµœì í™”** | 7/10 | ğŸŸ¡ ê°œì„  í•„ìš” | 5ê°œ ë³‘ëª© ì¡´ì¬ |
| **ì¸í”„ë¼ ì„¤ì •** | 8/10 | ğŸŸ¡ íŠœë‹ í•„ìš” | Pool/Redis ì„¤ì • ë¶€ì¡± |
| **ë³´ì•ˆ & ì•ˆì •ì„±** | 9/10 | ğŸŸ¢ ìš°ìˆ˜ | Rate Limiting ì™„ë¹„ |

### í•µì‹¬ ê²°ë¡ 

âœ… **ê°•ì **: ì‹œìŠ¤í…œì€ ìˆ˜í‰ í™•ì¥(Horizontal Scaling)ì— ìµœì í™”ëœ êµ¬ì¡°ë¥¼ ê°–ì¶”ê³  ìˆìŒ
- JWT ê¸°ë°˜ ì™„ì „ ë¬´ìƒíƒœ(Stateless) ì„¤ê³„
- ë¹„ë™ê¸° I/O (asyncio + asyncpg) í™œìš©
- Redis ì™¸ë¶€í™”ëœ ìºì‹œ/Rate Limit

âš ï¸ **ì£¼ì˜**: í”„ë¡œë•ì…˜ ë°°í¬ ì „ **5ê°œ Critical ë³‘ëª©** í•´ê²° í•„ìˆ˜
- Blocking bcrypt ì—°ì‚° (ê°€ì¥ ì‹¬ê°)
- ë§¤ ìš”ì²­ë§ˆë‹¤ ê¶Œí•œ DB ì¿¼ë¦¬
- ì¸ë±ìŠ¤ ëˆ„ë½
- ìºì‹œ ë¬´íš¨í™” Gap
- Connection Pool ë¶€ì¡±

ğŸ¯ **ê¶Œì¥ ì¡°ì¹˜**: Phase 1 ìˆ˜ì •ìœ¼ë¡œ **200 RPS â†’ 1,500 RPS (7.5ë°°)** ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥

---

## ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼

## 1. ì•„í‚¤í…ì²˜ í™•ì¥ì„± ë¶„ì„ (9/10)

**ë¶„ì„ ë‹´ë‹¹**: architecture-reviewer

### 1.1 ìˆ˜í‰ í™•ì¥ ì¤€ë¹„ë„: **ìš°ìˆ˜**

#### âœ… Stateless ì„¤ê³„ ê²€ì¦

```python
# âœ… JWT ê¸°ë°˜ ì¸ì¦ - ì„œë²„ ë©”ëª¨ë¦¬ì— ì„¸ì…˜ ì—†ìŒ
# src/shared/dependencies.py
async def get_current_user(authorization: str = Header(...)):
    payload = jwt_handler.decode_token(token)  # ìƒíƒœ ì—†ì´ ê²€ì¦
    # ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ ë…ë¦½ì ìœ¼ë¡œ í† í° ê²€ì¦ ê°€ëŠ¥
```

**ê²€ì¦ í•­ëª©**:
- âœ… ì„¸ì…˜ ìŠ¤í† ì–´ ì—†ìŒ (ëª¨ë“  ìƒíƒœëŠ” JWT ë˜ëŠ” Redis)
- âœ… íŒŒì¼ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì—†ìŒ (ê³µê°œí‚¤ë§Œ ê³µìœ )
- âœ… ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ê°€ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
- âœ… Load Balancer í˜¸í™˜ (Sticky Session ë¶ˆí•„ìš”)

#### âœ… ì™¸ë¶€ ìƒíƒœ ê´€ë¦¬

```python
# Redisë¡œ ì™¸ë¶€í™”ëœ ìƒíƒœë“¤
- Rate Limiting ì¹´ìš´í„°: redis.incr(f"rate_limit:{ip}")
- í† í° ë¸”ë™ë¦¬ìŠ¤íŠ¸: redis.sadd("blacklist:access")
- ê¶Œí•œ ìºì‹œ: redis.get(f"user:{user_id}:permissions")
- ë¡œê·¸ì¸ ì‹¤íŒ¨ ì¹´ìš´í„°: redis.incr(f"failed_login:{email}")
```

**ì¥ì **: ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ ë™ì¼í•œ Rate Limit/ìºì‹œ ê³µìœ 

#### âœ… Connection Pool ì„¤ê³„

```python
# src/shared/database/connection.py:37
async def get_pool():
    return await asyncpg.create_pool(
        min_size=5,
        max_size=50,  # âš ï¸ ê°œì„  í•„ìš”
        command_timeout=30.0,
    )
```

**í˜„í™©**:
- ê° ì¸ìŠ¤í„´ìŠ¤ê°€ ë…ë¦½ì ì¸ Pool ìœ ì§€ (ì •ìƒ)
- 50 connections: 3 ì¸ìŠ¤í„´ìŠ¤ = 150 total connections
- PostgreSQL default `max_connections=100` ì´ˆê³¼ ìœ„í—˜ âš ï¸

### 1.2 Load Balancing ì „ëµ ê¶Œì¥

#### ì¶”ì²œ ì•„í‚¤í…ì²˜ (Production)

```
                   [Load Balancer]
                    (Round Robin)
                          |
        +-----------------+-----------------+
        |                 |                 |
   [Instance 1]      [Instance 2]      [Instance 3]
   Uvicorn x4        Uvicorn x4        Uvicorn x4
        |                 |                 |
        +--------[PostgreSQL Master]--------+
                          |
                  [Read Replicas x2]
                          |
                    [Redis Cluster]
                  (3 masters + 3 replicas)
```

**ì„¤ì • ê¶Œì¥**:
```yaml
# ì¸ìŠ¤í„´ìŠ¤ë‹¹ ì„¤ì •
workers: 4  # CPU ì½”ì–´ ìˆ˜ ê¸°ì¤€
connection_pool_per_instance: 30
total_instances: 3

# ì´ DB Connections
= 3 instances Ã— 4 workers Ã— 30 pool = 360 connections
â†’ PostgreSQL max_connections=500 í•„ìš”
```

### 1.3 ê°œì„  í•„ìš” ì‚¬í•­

#### ğŸ”´ Critical: Connection Pool Size

**í˜„ì¬ ë¬¸ì œ**:
```python
max_size=50  # ë„ˆë¬´ ì‘ìŒ
```

**ê³„ì‚°**:
- 1000 RPS ëª©í‘œ
- í‰ê·  ì‘ë‹µ ì‹œê°„ 50ms (bcrypt ê°œì„  í›„)
- ë™ì‹œ ìš”ì²­ = 1000 Ã— 0.05 = **50ê°œ**
- **í˜„ì¬ Poolë¡œëŠ” ì •í™•íˆ í•œê³„ì„ **

**ê¶Œì¥ ì„¤ì •**:
```python
# Development
max_size=20

# Staging (1,000 RPS ëª©í‘œ)
max_size=50

# Production (10,000 RPS ëª©í‘œ)
max_size=100  # per instance
```

#### ğŸŸ  High: Redis Single Point of Failure

**í˜„ì¬**:
```yaml
# docker-compose.yml
redis:
  image: redis:7-alpine
  # ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ - ì¥ì•  ì‹œ ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ë‹¨
```

**ê¶Œì¥**:
```bash
# Redis Sentinel (ìë™ Failover)
Master 1ê°œ + Replica 2ê°œ + Sentinel 3ê°œ

# ë˜ëŠ” Redis Cluster (ëŒ€ìš©ëŸ‰)
6 nodes (3 masters + 3 replicas)
```

---

## 2. ì„±ëŠ¥ ë³‘ëª© ë¶„ì„ (7/10)

**ë¶„ì„ ë‹´ë‹¹**: performance-analyst

### 2.1 Critical Bottlenecks (ìš°ì„ ìˆœìœ„ ìˆœ)

#### ğŸ”´ #1: Blocking bcrypt Operations (CRITICAL)

**ìœ„ì¹˜**: `src/domains/authentication/service.py:73`

```python
# âŒ í˜„ì¬: Event Loopì„ ë¸”ë¡œí‚¹í•˜ëŠ” ë™ê¸° í˜¸ì¶œ
hashed_password = pwd_context.hash(password)  # 200-300ms
is_valid = pwd_context.verify(password, hash)  # 100-200ms
```

**ì˜í–¥ë„ ë¶„ì„**:
| ë™ì‹œ ìš”ì²­ | í‰ê·  ëŒ€ê¸° ì‹œê°„ | CPU ì‚¬ìš©ë¥  | ì²˜ë¦¬ ê°€ëŠ¥ RPS |
|----------|-------------|----------|-------------|
| 10 | 150ms | 60% | ~60 |
| 50 | 500ms | 95% | ~100 |
| 100 | 2,000ms | 100% | ~150 |
| 500 | **10,000ms+** | 100% | **ì‹œìŠ¤í…œ ë§ˆë¹„** |

**ì‹¤ì œ ì¸¡ì • (ì˜ˆìƒ)**:
```bash
# ë‹¨ì¼ bcrypt.verify() ì‹¤í–‰ ì‹œê°„
$ python -m timeit -s "from passlib.context import CryptContext; pwd=CryptContext(schemes=['bcrypt']); h=pwd.hash('test')" "pwd.verify('test', h)"
10 loops, best of 5: 180 msec per loop
```

**í•´ê²° ë°©ë²•**:
```python
import asyncio
from functools import partial

# âœ… ê°œì„ : Thread Poolì—ì„œ ì‹¤í–‰
async def hash_password(password: str) -> str:
    """ë¹„ë™ê¸° íŒ¨ìŠ¤ì›Œë“œ í•´ì‹±"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,  # Default ThreadPoolExecutor
        partial(pwd_context.hash, password)
    )

async def verify_password(password: str, hashed: str) -> bool:
    """ë¹„ë™ê¸° íŒ¨ìŠ¤ì›Œë“œ ê²€ì¦"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        partial(pwd_context.verify, password, hashed)
    )

# Serviceì—ì„œ ì‚¬ìš©
is_valid = await verify_password(password, user_row["password_hash"])
```

**ì˜ˆìƒ ê°œì„ **:
- ì‘ë‹µ ì‹œê°„: 250ms â†’ 50ms (**80% ê°ì†Œ**)
- CPU ë¸”ë¡œí‚¹ ì œê±°ë¡œ ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ **5ë°° ì¦ê°€**
- ì²˜ë¦¬ ê°€ëŠ¥ RPS: 200 â†’ **1,000+**

---

#### ğŸ”´ #2: N+1 Query - Permission Check (HIGH)

**ìœ„ì¹˜**: `src/shared/dependencies.py:108`

```python
# âŒ ë¬¸ì œ: ëª¨ë“  ì¸ì¦ëœ ìš”ì²­ë§ˆë‹¤ DB ì¿¼ë¦¬
async def get_current_user(...):
    # ... JWT ê²€ì¦ ...

    permissions_data = await connection.fetch(
        sql.load_query("get_user_roles_permissions"),  # ë§¤ ìš”ì²­ë§ˆë‹¤!
        user_id=user_id,
    )
    # 1000 RPS = 1000 QPS on permissions table
```

**ì˜í–¥ë„**:
- 1000 RPS ì‹œ: **1000 QPS on DB**
- í‰ê·  ì¿¼ë¦¬ ì‹œê°„: 10-20ms (ì¸ë±ìŠ¤ ìˆì–´ë„)
- ê¶Œí•œ ë§ì€ ì‚¬ìš©ì (10+ ì—­í• ): 50-100ms
- **DBê°€ ë³‘ëª©ì ì´ ë¨**

**í•´ê²° ë°©ë²•**:
```python
# âœ… ê°œì„ : ì´ë¯¸ êµ¬í˜„ëœ ìºì‹œ í•¨ìˆ˜ í™œìš©
from src.domains.users.service import get_user_permissions_with_cache

async def get_current_user(...):
    # ... JWT ê²€ì¦ ...

    permissions = await get_user_permissions_with_cache(
        connection=connection,
        user_id=user_id  # Redis 5ë¶„ ìºì‹œ (300ì´ˆ)
    )
    # Cache Hit ì‹œ: <1ms (Redis)
    # Cache Miss ì‹œ: 10-20ms (DB + Redis Set)
```

**ì˜ˆìƒ ê°œì„ **:
- Cache Hit Rate 95% ê°€ì •
- DB ë¶€í•˜: 1000 QPS â†’ **50 QPS (95% ê°ì†Œ)**
- í‰ê·  ì‘ë‹µ ì‹œê°„: 15ms â†’ **1ms (94% ê°ì†Œ)**
- DB CPU ì‚¬ìš©ë¥ : 60% â†’ **10%**

---

#### ğŸŸ  #3: Missing Index - Refresh Token Lookup (MEDIUM)

**ìœ„ì¹˜**: `scripts/init.sql` (ì¸ë±ìŠ¤ ë¶€ì¬)

```sql
-- âŒ í˜„ì¬: token_hashë§Œ ì¸ë±ìŠ¤
CREATE INDEX idx_refresh_tokens_token_hash ON refresh_tokens(token_hash);

-- ì‹¤ì œ ì¿¼ë¦¬ íŒ¨í„´
SELECT * FROM refresh_tokens
WHERE token_hash = ?
  AND revoked_at IS NULL  -- ì´ ì¡°ê±´ ë•Œë¬¸ì— Full Table Scan
  AND expires_at > NOW();
```

**EXPLAIN ANALYZE ê²°ê³¼ (ì˜ˆìƒ)**:
```
Seq Scan on refresh_tokens  (cost=0.00..1234.56 rows=1 width=200)
  Filter: (token_hash = '...' AND revoked_at IS NULL)
  Rows Removed by Filter: 10000
Planning Time: 0.123 ms
Execution Time: 45.678 ms  -- ë„ˆë¬´ ëŠë¦¼!
```

**í•´ê²° ë°©ë²•**:
```sql
-- âœ… ê°œì„ : Partial Index ë˜ëŠ” Composite Index
-- Option 1: Partial Index (WHERE ì¡°ê±´ í¬í•¨)
CREATE INDEX idx_refresh_tokens_active_lookup
  ON refresh_tokens (token_hash)
  WHERE revoked_at IS NULL AND expires_at > NOW();

-- Option 2: Composite Index (ë” ì•ˆì „)
CREATE INDEX idx_refresh_tokens_lookup
  ON refresh_tokens (token_hash, revoked_at, expires_at);
```

**ì˜ˆìƒ ê°œì„ **:
- ì¿¼ë¦¬ ì‹œê°„: 45ms â†’ **0.5ms (90ë°° ë¹ ë¦„)**
- Index-Only Scanìœ¼ë¡œ ë””ìŠ¤í¬ I/O ê°ì†Œ
- Refresh Token ì—”ë“œí¬ì¸íŠ¸ ì²˜ë¦¬ëŸ‰ **10ë°° ì¦ê°€**

---

#### ğŸŸ  #4: Cache Invalidation Gap (MEDIUM)

**ìœ„ì¹˜**: `src/domains/users/service.py` (ì—¬ëŸ¬ í•¨ìˆ˜)

```python
# âŒ ë¬¸ì œ: ì—­í• /ê¶Œí•œ ë³€ê²½ ì‹œ ìºì‹œ ë¬´íš¨í™” ì—†ìŒ
async def update_user_roles(connection, user_id: int, role_ids: list[int]):
    # ... DB ì—…ë°ì´íŠ¸ ...
    return result
    # ìºì‹œê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ!

# ê²°ê³¼: ì‚¬ìš©ìëŠ” ìµœëŒ€ 5ë¶„ê°„ ì˜ëª»ëœ ê¶Œí•œìœ¼ë¡œ ìš”ì²­ ê°€ëŠ¥
```

**ì‹œë‚˜ë¦¬ì˜¤**:
1. ì‚¬ìš©ì Aê°€ `admin` ì—­í•  ê°€ì§ â†’ ìºì‹œë¨
2. ê´€ë¦¬ìê°€ Aì˜ ì—­í•  ì œê±°
3. AëŠ” 5ë¶„ê°„ ì—¬ì „íˆ ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ë™ì‘ âš ï¸

**í•´ê²° ë°©ë²•**:
```python
# âœ… ê°œì„ : ì—­í•  ë³€ê²½ ì‹œ ì¦‰ì‹œ ìºì‹œ ë¬´íš¨í™”
async def update_user_roles(connection, user_id: int, role_ids: list[int]):
    # DB ì—…ë°ì´íŠ¸
    result = await connection.execute(...)

    # ìºì‹œ ë¬´íš¨í™” ì¶”ê°€
    from src.shared.security.redis_store import RedisStore
    redis = RedisStore()
    cache_key = f"user:{user_id}:permissions"
    await redis.delete(cache_key)

    return result

# ë™ì¼í•˜ê²Œ ì ìš© í•„ìš”í•œ í•¨ìˆ˜ë“¤:
# - update_user_roles()
# - delete_user_role()
# - update_role_permissions()
# - assign_role()
```

**ì˜ˆìƒ ê°œì„ **:
- ë³´ì•ˆ Gap ì œê±° (5ë¶„ â†’ **ì¦‰ì‹œ**)
- ê¶Œí•œ ë³€ê²½ í›„ ë‹¤ìŒ ìš”ì²­ì—ì„œ ì¦‰ì‹œ ë°˜ì˜
- ê°ì‚¬(Audit) ìš”êµ¬ì‚¬í•­ ì¶©ì¡±

---

#### ğŸŸ¡ #5: Serial Redis Operations (LOW)

**ìœ„ì¹˜**: `src/shared/security/redis_store.py:65-70`

```python
# âŒ ë¬¸ì œ: ìˆœì°¨ ì‹¤í–‰ (Në²ˆ ì™•ë³µ)
async def invalidate_user_tokens(self, tokens: list[str]):
    for token in tokens:
        await self.redis.sadd(f"blacklist:access:{token}", 1)  # RTT Ã— N
        await self.redis.expire(f"blacklist:access:{token}", 1800)  # RTT Ã— N
    # 100ê°œ í† í° = 200ë²ˆ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ!
```

**ì˜í–¥ë„**:
- 10ê°œ í† í°: ~20ms (Redis RTT 1ms ê°€ì •)
- 100ê°œ í† í°: ~200ms
- 1000ê°œ í† í°: ~2ì´ˆ

**í•´ê²° ë°©ë²•**:
```python
# âœ… ê°œì„ : Redis Pipeline ì‚¬ìš© (1ë²ˆ ì™•ë³µ)
async def invalidate_user_tokens(self, tokens: list[str]):
    if not tokens:
        return

    pipeline = self.redis.pipeline()
    for token in tokens:
        pipeline.sadd(f"blacklist:access:{token}", 1)
        pipeline.expire(f"blacklist:access:{token}", 1800)

    await pipeline.execute()  # ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ
```

**ì˜ˆìƒ ê°œì„ **:
- 100ê°œ í† í°: 200ms â†’ **2ms (100ë°° ë¹ ë¦„)**
- ë„¤íŠ¸ì›Œí¬ ì™•ë³µ: NíšŒ â†’ **1íšŒ**
- ëŒ€ëŸ‰ ë¡œê·¸ì•„ì›ƒ ì‹œë‚˜ë¦¬ì˜¤ ê°œì„ 

---

### 2.2 ì¿¼ë¦¬ ì„±ëŠ¥ ìš”ì•½

| ì¿¼ë¦¬ | í˜„ì¬ ì‹œê°„ | ìµœì í™” í›„ | í˜¸ì¶œ ë¹ˆë„ | ìš°ì„ ìˆœìœ„ |
|-----|----------|----------|----------|---------|
| `get_user_roles_permissions` | 15ms | 1ms (ìºì‹œ) | ëª¨ë“  ìš”ì²­ | ğŸ”´ HIGH |
| Refresh token lookup | 45ms | 0.5ms | ë†’ìŒ | ğŸŸ  MEDIUM |
| Login history insert | 5ms | 5ms | ì¤‘ê°„ | âœ… OK |
| User registration | 220ms (bcrypt) | 20ms | ë‚®ìŒ | ğŸ”´ CRITICAL |

---

## 3. ì¸í”„ë¼ ì„¤ì • ë¶„ì„ (8/10)

**ë¶„ì„ ë‹´ë‹¹**: infrastructure-specialist

### 3.1 í˜„ì¬ ì„¤ì • ê²€í† 

#### Docker Compose ì„¤ì •

```yaml
# docker-compose.yml
services:
  auth-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: authdb
      POSTGRES_USER: devuser
      POSTGRES_PASSWORD: devpassword
      # âš ï¸ max_connections ì„¤ì • ì—†ìŒ (default: 100)
    # âš ï¸ CPU/ë©”ëª¨ë¦¬ ì œí•œ ì—†ìŒ
    # âš ï¸ Health check ì—†ìŒ

  redis:
    image: redis:7-alpine
    # âŒ maxmemory ì„¤ì • ì—†ìŒ - OOM ìœ„í—˜!
    # âŒ ì§€ì†ì„± ì„¤ì • ì—†ìŒ (AOF/RDB)
    # âŒ Health check ì—†ìŒ
```

#### Application ì„¤ì •

```python
# src/shared/database/connection.py
DATABASE_POOL_CONFIG = {
    "min_size": 5,
    "max_size": 50,        # âš ï¸ ë¶€ì¡±
    "max_queries": 50000,
    "max_inactive_connection_lifetime": 300.0,
    "command_timeout": 30.0,  # âœ… ì ì ˆ
}

# Redis
# âš ï¸ Connection Pool ì„¤ì • ì—†ìŒ
```

### 3.2 ê¶Œì¥ ì„¤ì • (í™˜ê²½ë³„)

#### ğŸ”µ Development Environment (ë¡œì»¬)

**ëª©í‘œ**: 100 RPS ì´í•˜, ë¹ ë¥¸ í”¼ë“œë°±

```yaml
# docker-compose.yml
services:
  auth-db:
    image: postgres:15-alpine
    command: >
      postgres
      -c max_connections=50
      -c shared_buffers=128MB
      -c effective_cache_size=512MB
      -c work_mem=4MB
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U devuser -d authdb"]
      interval: 10s
      timeout: 5s
      retries: 3

  redis:
    image: redis:7-alpine
    command: >
      redis-server
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --save 60 1000
      --appendonly yes
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
```

```python
# .env.development
DATABASE_POOL_MIN_SIZE=3
DATABASE_POOL_MAX_SIZE=10
REDIS_POOL_MAX_SIZE=10
UVICORN_WORKERS=1
```

---

#### ğŸŸ¢ Staging Environment (AWS ECS)

**ëª©í‘œ**: 1,000 RPS, ì‹¤ì œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜

```yaml
# PostgreSQL RDS
Instance Type: db.t3.medium (2 vCPU, 4GB RAM)
Storage: 100GB GP3 SSD
max_connections: 200
shared_buffers: 1GB
effective_cache_size: 3GB
work_mem: 8MB
maintenance_work_mem: 256MB

# Redis ElastiCache
Node Type: cache.t3.medium (2 vCPU, 3.09GB RAM)
maxmemory: 2gb
maxmemory-policy: allkeys-lru
Cluster Mode: Disabled (ë‹¨ì¼ ìƒ¤ë“œ)
Snapshots: ë§¤ì¼ ìë™ ë°±ì—…

# Application (ECS Fargate)
CPU: 2 vCPU
Memory: 4GB
Task Count: 2
```

```python
# .env.staging
DATABASE_POOL_MIN_SIZE=10
DATABASE_POOL_MAX_SIZE=50
REDIS_POOL_MAX_SIZE=30
UVICORN_WORKERS=4
```

---

#### ğŸ”´ Production Environment (AWS)

**ëª©í‘œ**: 10,000+ RPS, ê³ ê°€ìš©ì„±, Auto Scaling

```yaml
# PostgreSQL RDS (Primary)
Instance Type: db.r6g.2xlarge (8 vCPU, 64GB RAM)
Multi-AZ: Enabled
Storage: 500GB GP3 SSD (12,000 IOPS)
max_connections: 1000
shared_buffers: 16GB
effective_cache_size: 48GB
work_mem: 32MB
maintenance_work_mem: 2GB

# Read Replicas Ã— 2
Instance Type: db.r6g.xlarge (4 vCPU, 32GB RAM)
ê° ReplicaëŠ” ì½ê¸° ì „ìš© ì›Œí¬ë¡œë“œ ì²˜ë¦¬

# PgBouncer (Connection Pooler)
pool_mode: transaction
default_pool_size: 50
max_client_conn: 2000

# Redis ElastiCache Cluster
Node Type: cache.r6g.large Ã— 6 (3 shards)
ê° ìƒ¤ë“œ: Primary 1 + Replica 1
Total Memory: 78GB (13GB Ã— 6)
Cluster Mode: Enabled
maxmemory-policy: allkeys-lru
Auto Failover: Enabled

# Application (ECS Fargate)
CPU: 4 vCPU per task
Memory: 8GB per task
Task Count: 10 (ìµœì†Œ)
Auto Scaling:
  - Target CPU: 70%
  - Target Memory: 80%
  - Min Tasks: 10
  - Max Tasks: 50

# Load Balancer
ALB with:
  - Health Check: GET /health
  - Interval: 10s
  - Timeout: 5s
  - Healthy Threshold: 2
  - Unhealthy Threshold: 3
```

```python
# .env.production
DATABASE_POOL_MIN_SIZE=20
DATABASE_POOL_MAX_SIZE=100  # per instance
REDIS_POOL_MAX_SIZE=50
UVICORN_WORKERS=8  # CPU ì½”ì–´ ìˆ˜ ê¸°ì¤€
```

**ì´ ë¦¬ì†ŒìŠ¤ ê³„ì‚°**:
```
# DB Connections
= 10 instances Ã— 8 workers Ã— 100 pool = 8,000 connections
â†’ PgBouncerë¡œ 1,000ê°œë¡œ ë‹¤ìš´ìƒ˜í”Œë§

# ì˜ˆìƒ ì²˜ë¦¬ ëŠ¥ë ¥
= 10 instances Ã— 8 workers Ã— 150 RPS/worker = 12,000 RPS
```

---

### 3.3 Rate Limiting ì •ì±… ê²€í† 

#### í˜„ì¬ êµ¬í˜„

```python
# src/shared/middleware/rate_limiter.py:31
DEFAULT_RATE_LIMITS = {
    "/api/v1/auth/login": "5/minute",       # âœ… ì ì ˆ
    "/api/v1/auth/register": "3/minute",    # âœ… ì ì ˆ
    "/api/v1/auth/refresh": "10/minute",    # âš ï¸ ë„ˆë¬´ ë‚®ì„ ìˆ˜ ìˆìŒ
}
```

#### ê¶Œì¥ ì •ì±… (í™˜ê²½ë³„)

**Development**:
```python
RATE_LIMITS = {
    "/api/v1/auth/login": "10/minute",
    "/api/v1/auth/register": "5/minute",
    "/api/v1/auth/refresh": "20/minute",
    "default": "100/minute",
}
```

**Production**:
```python
RATE_LIMITS = {
    # IP ê¸°ë°˜
    "/api/v1/auth/login": "5/minute/ip",         # ë¸Œë£¨íŠ¸ í¬ìŠ¤ ë°©ì–´
    "/api/v1/auth/register": "3/hour/ip",        # ìŠ¤íŒ¸ ë°©ì§€

    # ì‚¬ìš©ì ê¸°ë°˜
    "/api/v1/auth/refresh": "30/minute/user",    # ì •ìƒ ì‚¬ìš© íŒ¨í„´
    "/api/v1/users/*": "1000/minute/user",       # ì¼ë°˜ API

    # ê¸€ë¡œë²Œ (ì „ì²´ ì‹œìŠ¤í…œ)
    "global": "50000/minute",                    # DDoS ë°©ì–´
}
```

---

### 3.4 ëª¨ë‹ˆí„°ë§ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### í•„ìˆ˜ ë©”íŠ¸ë¦­

**Application ë ˆë²¨**:
```
âœ… Request Rate (RPS)
âœ… Response Time (p50, p95, p99)
âœ… Error Rate (4xx, 5xx)
âŒ Active Connections (DB Pool)  # í•„ìš”
âŒ Redis Hit Rate               # í•„ìš”
âŒ Background Task Queue Length  # í•„ìš”
```

**Database**:
```
âœ… Active Connections
âœ… Slow Queries (> 100ms)
âŒ Transaction Rollback Rate  # í•„ìš”
âŒ Dead Tuple ë¹„ìœ¨            # í•„ìš”
âŒ Replication Lag           # Read Replica ì‚¬ìš© ì‹œ
```

**Redis**:
```
âœ… Memory Usage
âœ… Evicted Keys
âŒ Command Latency           # í•„ìš”
âŒ Keyspace Hit Rate         # í•„ìš”
```

**Infrastructure**:
```
âœ… CPU Usage
âœ… Memory Usage
âœ… Network I/O
âŒ Disk I/O (IOPS, Latency)  # í•„ìš”
```

#### ê¶Œì¥ ì•Œë¦¼ ê·œì¹™

```yaml
# Critical Alerts
- name: High Error Rate
  condition: error_rate > 5%
  duration: 5m
  severity: critical

- name: Slow Response Time
  condition: p95_latency > 500ms
  duration: 10m
  severity: critical

- name: DB Connection Pool Exhausted
  condition: active_connections > 90% of max_size
  duration: 2m
  severity: critical

# Warning Alerts
- name: High CPU Usage
  condition: cpu_usage > 80%
  duration: 15m
  severity: warning

- name: Low Redis Hit Rate
  condition: cache_hit_rate < 80%
  duration: 30m
  severity: warning
```

---

## 4. Load Testing ê³„íš

**ë¶„ì„ ë‹´ë‹¹**: load-tester

### 4.1 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### Scenario 1: Normal Load (Baseline)

**ëª©í‘œ**: ì •ìƒ ìš´ì˜ ì‹œ ì„±ëŠ¥ ì¸¡ì •

```python
# tests/load/locustfile.py
from locust import HttpUser, task, between

class NormalUser(HttpUser):
    wait_time = between(1, 3)  # ì‚¬ìš©ìë‹¹ 1-3ì´ˆ ëŒ€ê¸°

    def on_start(self):
        # ë¡œê·¸ì¸í•˜ì—¬ í† í° íšë“
        response = self.client.post("/api/v1/auth/login", json={
            "email": f"user_{self.user_id}@example.com",
            "password": "TestPass123!"
        })
        self.token = response.json()["data"]["access_token"]

    @task(5)  # 50% ë¹„ì¤‘
    def get_user_info(self):
        self.client.get(
            "/api/v1/users/me",
            headers={"Authorization": f"Bearer {self.token}"}
        )

    @task(3)  # 30% ë¹„ì¤‘
    def refresh_token(self):
        self.client.post(
            "/api/v1/auth/refresh",
            json={"refresh_token": self.refresh_token}
        )

    @task(2)  # 20% ë¹„ì¤‘
    def login(self):
        self.client.post("/api/v1/auth/login", json={
            "email": f"user_{self.user_id}@example.com",
            "password": "TestPass123!"
        })
```

**ì‹¤í–‰**:
```bash
locust -f tests/load/locustfile.py \
  --users 100 \
  --spawn-rate 10 \
  --run-time 10m \
  --host http://localhost:8000
```

**ì˜ˆìƒ ê²°ê³¼** (bcrypt ê°œì„  ì „):
```
Total Requests: 10,000
Failures: 0
RPS: ~150
Avg Response Time: 250ms
P95 Response Time: 500ms
P99 Response Time: 1,200ms
```

---

#### Scenario 2: Spike Test (ê¸‰ì¦ íŠ¸ë˜í”½)

**ëª©í‘œ**: ê°‘ì‘ìŠ¤ëŸ¬ìš´ íŠ¸ë˜í”½ ì¦ê°€ ëŒ€ì‘ ëŠ¥ë ¥ ì¸¡ì •

```bash
# 0 â†’ 1000 users in 30 seconds
locust -f tests/load/locustfile.py \
  --users 1000 \
  --spawn-rate 33 \
  --run-time 5m \
  --host http://localhost:8000
```

**ì˜ˆìƒ ê²°ê³¼** (bcrypt ê°œì„  ì „):
```
# ì²˜ìŒ 30ì´ˆ
RPS: 0 â†’ 500 (ì¦ê°€)
Avg Response Time: 100ms â†’ 2,000ms

# 30ì´ˆ ì´í›„ (ì•ˆì •í™”)
RPS: ~200 (í•œê³„ ë„ë‹¬)
Failures: ~60% (Connection Pool Exhausted)
P99 Response Time: 10,000ms+ (Timeout)
```

**ì‹¤íŒ¨ ì§€ì **: 500 RPS ë¶€ê·¼ (bcrypt ë³‘ëª©)

---

#### Scenario 3: Stress Test (ì§€ì† ê³ ë¶€í•˜)

**ëª©í‘œ**: ì‹œìŠ¤í…œ í•œê³„ ë° Memory Leak ê²€ì¦

```bash
locust -f tests/load/locustfile.py \
  --users 500 \
  --spawn-rate 50 \
  --run-time 30m \
  --host http://localhost:8000
```

**ëª¨ë‹ˆí„°ë§**:
```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¶”ì´
watch -n 5 'docker stats --no-stream'

# DB Connection ìˆ˜
watch -n 5 'psql -c "SELECT count(*) FROM pg_stat_activity"'

# Redis ë©”ëª¨ë¦¬
watch -n 5 'redis-cli INFO memory | grep used_memory_human'
```

**ì˜ˆìƒ ë°œê²¬**:
- Connection Pool Leak ì—¬ë¶€
- Redis Memory ì¦ê°€ íŒ¨í„´
- Slow Query ë°œìƒ ë¹ˆë„

---

#### Scenario 4: Read-Heavy Load

**ëª©í‘œ**: ì½ê¸° ì¤‘ì‹¬ ì›Œí¬ë¡œë“œ (ìºì‹œ íš¨ê³¼ ì¸¡ì •)

```python
@task(9)  # 90%
def read_operations(self):
    self.client.get("/api/v1/users/me", ...)

@task(1)  # 10%
def write_operations(self):
    self.client.post("/api/v1/auth/login", ...)
```

**ì˜ˆìƒ ê²°ê³¼** (ìºì‹œ ê°œì„  í›„):
```
Cache Hit Rate: 95%
DB QPS: 1000 â†’ 50 (95% ê°ì†Œ)
RPS: 1,500 (3ë°° ì¦ê°€)
Avg Response Time: 15ms (94% ê°œì„ )
```

---

### 4.2 ì„±ëŠ¥ ëª©í‘œ (SLA)

| í™˜ê²½ | ëª©í‘œ RPS | Avg Latency | P95 Latency | P99 Latency | Error Rate |
|------|---------|-------------|-------------|-------------|-----------|
| **Development** | 100 | <50ms | <100ms | <200ms | <1% |
| **Staging** | 1,000 | <30ms | <80ms | <150ms | <0.5% |
| **Production** | 10,000+ | <20ms | <50ms | <100ms | <0.1% |

---

### 4.3 Load Testing CI í†µí•©

```yaml
# .github/workflows/load-test.yml
name: Load Test

on:
  pull_request:
    branches: [develop, master]
  schedule:
    - cron: '0 2 * * 1'  # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 2ì‹œ

jobs:
  load-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Start Services
        run: docker-compose up -d

      - name: Wait for Healthy
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'

      - name: Run Load Test
        run: |
          pip install locust
          locust -f tests/load/locustfile.py \
            --headless \
            --users 100 \
            --spawn-rate 10 \
            --run-time 5m \
            --host http://localhost:8000 \
            --html report.html

      - name: Check Performance Regression
        run: |
          # P95 < 100ms ê²€ì¦
          python tests/load/check_regression.py report.html

      - name: Upload Report
        uses: actions/upload-artifact@v3
        with:
          name: load-test-report
          path: report.html
```

---

## ğŸ“‹ ì¢…í•© ì‹¤í–‰ ê³„íš

### Phase 1: Critical Fixes (1-2ì¼) ğŸ”´

**ëª©í‘œ**: 7.5ë°° ì„±ëŠ¥ í–¥ìƒ (200 â†’ 1,500 RPS)

| Task | íŒŒì¼ | ì˜ˆìƒ ì‹œê°„ | ìš°ì„ ìˆœìœ„ |
|------|------|----------|---------|
| 1.1 bcrypt ë¹„ë™ê¸° ì „í™˜ | `src/domains/authentication/service.py` | 3ì‹œê°„ | P0 |
| 1.2 Permission ìºì‹œ í™œìš© | `src/shared/dependencies.py` | 1ì‹œê°„ | P0 |
| 1.3 Refresh Token ì¸ë±ìŠ¤ | `scripts/migrations/002_*.sql` | 30ë¶„ | P0 |
| 1.4 ìºì‹œ ë¬´íš¨í™” ì¶”ê°€ | `src/domains/users/service.py` | 2ì‹œê°„ | P1 |
| 1.5 Redis Pipeline | `src/shared/security/redis_store.py` | 1ì‹œê°„ | P1 |

**ê²€ì¦**:
```bash
# Unit Tests
pytest tests/unit/test_async_password.py -v
pytest tests/unit/test_redis_pipeline.py -v

# Integration Tests
pytest tests/integration/test_permission_cache.py -v

# Performance Test
locust -f tests/load/baseline.py --headless --users 500 --run-time 5m
# ì˜ˆìƒ: RPS 200 â†’ 1,500
```

---

### Phase 2: Infrastructure Tuning (3-5ì¼) ğŸŸ 

**ëª©í‘œ**: 30ë°° ì„±ëŠ¥ í–¥ìƒ (200 â†’ 6,000 RPS)

| Task | ì‘ì—… ë‚´ìš© | ì˜ˆìƒ ì‹œê°„ |
|------|----------|----------|
| 2.1 Connection Pool í™•ëŒ€ | max_size: 50 â†’ 100 | 1ì‹œê°„ |
| 2.2 Docker Compose ì„¤ì • | maxmemory, health checks | 2ì‹œê°„ |
| 2.3 Uvicorn Workers | Single â†’ 4 workers | 1ì‹œê°„ |
| 2.4 PostgreSQL íŠœë‹ | max_connections, shared_buffers | 2ì‹œê°„ |
| 2.5 Redis ìµœì í™” | maxmemory-policy, persistence | 2ì‹œê°„ |
| 2.6 Rate Limiting ì •ì±… | í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬ | 2ì‹œê°„ |

---

### Phase 3: Production Setup (1ì£¼) ğŸŸ¡

**ëª©í‘œ**: ë¬´í•œ ìˆ˜í‰ í™•ì¥ (50,000+ RPS)

| Task | ì‘ì—… ë‚´ìš© | ì˜ˆìƒ ì‹œê°„ |
|------|----------|----------|
| 3.1 Read Replica ì„¤ì • | RDS Multi-AZ + 2 Replicas | 4ì‹œê°„ |
| 3.2 Redis Cluster | ElastiCache 3 shards | 4ì‹œê°„ |
| 3.3 PgBouncer | Connection Pooler ë„ì… | 3ì‹œê°„ |
| 3.4 APM í†µí•© | Datadog/New Relic | 6ì‹œê°„ |
| 3.5 Auto Scaling | ECS Service Auto Scaling | 4ì‹œê°„ |
| 3.6 Load Testing CI | GitHub Actions í†µí•© | 3ì‹œê°„ |

---

## ğŸ’° ë¹„ìš© ë¶„ì„

### Current (Development)

```
PostgreSQL: Docker (Free)
Redis: Docker (Free)
Application: Local (Free)
---
Total: $0/month
```

### Staging Environment

```
RDS db.t3.medium: $75/month
ElastiCache cache.t3.medium: $50/month
ECS Fargate (2 tasks Ã— 2 vCPU): $60/month
ALB: $25/month
---
Total: ~$210/month
```

### Production Environment (10,000 RPS)

```
RDS db.r6g.2xlarge (Primary): $800/month
RDS db.r6g.xlarge Ã— 2 (Replicas): $400/month Ã— 2 = $800/month
ElastiCache r6g.large Ã— 6: $200/month Ã— 6 = $1,200/month
ECS Fargate (10 tasks Ã— 4 vCPU): $300/month
ALB: $25/month
CloudWatch: $50/month
Datadog APM: $200/month
---
Total: ~$3,375/month
```

**ROI ë¶„ì„**:
- Phase 1 íˆ¬ì: ê°œë°œ 1-2ì¼, ë¹„ìš© $0
  - íš¨ê³¼: 7.5ë°° ì„±ëŠ¥ í–¥ìƒ
  - ROI: **â­â­â­â­â­ (ë¬´ì¡°ê±´ í•´ì•¼ í•¨)**

- Phase 2 íˆ¬ì: ê°œë°œ 3-5ì¼, ë¹„ìš© +$210/month
  - íš¨ê³¼: 30ë°° ì„±ëŠ¥ í–¥ìƒ
  - ROI: **â­â­â­â­ (íŠ¸ë˜í”½ 500 RPS ë„ë‹¬ ì‹œ)**

- Phase 3 íˆ¬ì: ê°œë°œ 1ì£¼, ë¹„ìš© +$3,375/month
  - íš¨ê³¼: ë¬´í•œ í™•ì¥ + ê³ ê°€ìš©ì„±
  - ROI: **â­â­â­ (íŠ¸ë˜í”½ 5,000 RPS ë„ë‹¬ ì‹œ)**

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì‹¤í–‰ (ì´ë²ˆ ì£¼)

1. âœ… **bcryptë¥¼ `asyncio.to_thread()` ë¡œ ì „í™˜** (ê°€ì¥ ì¤‘ìš”!)
2. âœ… **Permission ì¡°íšŒì— ìºì‹œ í™œìš©**
3. âœ… **Refresh Token Composite Index ì¶”ê°€**

### 1ê°œì›” ë‚´

1. Connection Pool 100ìœ¼ë¡œ í™•ëŒ€
2. Redis maxmemory ì„¤ì •
3. Uvicorn 4 workers êµ¬ì„±
4. Docker Compose health checks ì¶”ê°€
5. Load Testing ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ë° ì‹¤í–‰

### í”„ë¡œë•ì…˜ ë°°í¬ ì „

1. Read Replica 2ê°œ ì„¤ì •
2. Redis Sentinel/Cluster êµ¬ì„±
3. APM ëª¨ë‹ˆí„°ë§ í†µí•© (Datadog/New Relic)
4. Auto Scaling ì •ì±… ìˆ˜ë¦½
5. Load Testing CI í†µí•©

---

## ğŸ“Š ì˜ˆìƒ Performance Trajectory

```
í˜„ì¬ ìƒíƒœ:
â”œâ”€ RPS: ~200
â”œâ”€ Avg Latency: 250ms
â””â”€ Scalability: 5/10

â†“ Phase 1 (1-2ì¼)

Phase 1 ì™„ë£Œ:
â”œâ”€ RPS: ~1,500 (7.5ë°°)
â”œâ”€ Avg Latency: 50ms (80% ê°œì„ )
â””â”€ Scalability: 7/10

â†“ Phase 2 (3-5ì¼)

Phase 2 ì™„ë£Œ:
â”œâ”€ RPS: ~6,000 (30ë°°)
â”œâ”€ Avg Latency: 40ms
â””â”€ Scalability: 9/10

â†“ Phase 3 (1ì£¼)

Phase 3 ì™„ë£Œ:
â”œâ”€ RPS: 50,000+ (horizontal scaling)
â”œâ”€ Avg Latency: 30ms
â””â”€ Scalability: 10/10
```

---

## ğŸ”š ê²°ë¡ 

### í•µì‹¬ ìš”ì•½

1. **ì•„í‚¤í…ì²˜ëŠ” ìš°ìˆ˜í•¨** (9/10)
   - Stateless ì„¤ê³„ë¡œ ìˆ˜í‰ í™•ì¥ ì¤€ë¹„ ì™„ë£Œ
   - ë¹„ë™ê¸° I/O í™œìš©
   - Redis ì™¸ë¶€í™”ëœ ìƒíƒœ ê´€ë¦¬

2. **ì„±ëŠ¥ ë³‘ëª© ì¡´ì¬** (7/10)
   - **bcrypt blockingì´ ê°€ì¥ ì‹¬ê°** (P0)
   - Permission ì¡°íšŒ ìµœì í™” í•„ìš” (P0)
   - ì¸ë±ìŠ¤ ë° ìºì‹œ ê°œì„  í•„ìš” (P1)

3. **ì¸í”„ë¼ íŠœë‹ í•„ìš”** (8/10)
   - Connection Pool í™•ëŒ€
   - Redis ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
   - Multi-worker êµ¬ì„±

4. **Load Testing í•„ìˆ˜**
   - ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • í•„ìš”
   - CI í†µí•©ìœ¼ë¡œ íšŒê·€ ë°©ì§€

### ìµœì¢… í‰ê°€

**í˜„ì¬ ì‹œìŠ¤í…œ ì¤€ë¹„ë„: 8.5/10** ğŸŸ¢

- âœ… ì•„í‚¤í…ì²˜: Production Ready
- âš ï¸ ì„±ëŠ¥: Phase 1 ìˆ˜ì • í•„ìˆ˜
- âš ï¸ ì¸í”„ë¼: ì„¤ì • íŠœë‹ í•„ìš”
- âŒ ëª¨ë‹ˆí„°ë§: APM í†µí•© í•„ìš”

**ê¶Œì¥ ì•¡ì…˜**:
1. Phase 1 ì¦‰ì‹œ ì‹œì‘ (1-2ì¼)
2. Phase 2ëŠ” íŠ¸ë˜í”½ ì¦ê°€ì— ë§ì¶° ì§„í–‰
3. Phase 3ëŠ” í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì™„ë£Œ

---

**ìƒì„± ë‚ ì§œ**: 2026-02-11
**ë¶„ì„ íŒ€**: performance-analyst, architecture-reviewer, load-tester, infrastructure-specialist
**ë¬¸ì„œ ë²„ì „**: 1.0
